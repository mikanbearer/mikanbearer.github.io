---
title: "從零開始的Prometheus基本練習"
date: 2020-08-13T17:07:15+08:00
draft: false
categories: [Monitoring]
tags: [Prometheus]
isCJKLanguage: true
---
Prometheus是最近非常流行的Pull-based monitoring，主要的角色是以下兩者：
  
* Prometheus：監控方，定期收集資料並存在資料庫
* Exporter：被監控方，回傳監控方需要的資料
  
為了往後學習方便，先來實作一遍這個方便利用的工具

<!--more-->
Prometheus的基礎運用架構很單純，大在就像下圖：
  
![](0.png)
  
從圖中可見，Prometheus收集時間序列資料(metrics)都是由自己主動向Exporter發起的，這次大概會做這些：
  


* <a onclick="window.scrollTo({top: document.getElementById(1).offsetTop, behavior: 'smooth'})">啟動Prometheus</a>
* <a onclick="window.scrollTo({top: document.getElementById(2).offsetTop, behavior: 'smooth'})">啟動Exporter</a>
* <a onclick="window.scrollTo({top: document.getElementById(3).offsetTop, behavior: 'smooth'})">使用static config監控</a>
* <a onclick="window.scrollTo({top: document.getElementById(4).offsetTop, behavior: 'smooth'})">使用file-based service discovery取得target</a>
* <a onclick="window.scrollTo({top: document.getElementById(5).offsetTop, behavior: 'smooth'})">使用Pushgateway</a>
  

<br></br>
* <h3 id=1>啟動Prometheus</h3>
---
<br></br>
部屬Prometheus非常簡單，就只是binary配上一個設定檔，指令如下：
```
$ wget https://github.com/prometheus/prometheus/releases/download/v2.20.1/prometheus-2.20.1.linux-amd64.tar.gz
$ tar zxvf prometheus-2.20.1.linux-amd64.tar.gz
$ cd prometheus-2.20.1.linux-amd64
```
<br></br>
```:prometheus.yml {linenos=table, linenostart=1}
# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']
```
<br></br>
```
$ ./prometheus --config.file=prometheus.yml
```
<br></br>
使用cURL測試一下metrics
```
$ curl localhost:9090/metrics
# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 8.412e-06
go_gc_duration_seconds{quantile="0.25"} 6.8151e-05
go_gc_duration_seconds{quantile="0.5"} 0.000435588
go_gc_duration_seconds{quantile="0.75"} 0.000661594
go_gc_duration_seconds{quantile="1"} 0.001019489
go_gc_duration_seconds_sum 0.002193234
go_gc_duration_seconds_count 5
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
...
```
**就算加上下載，整個過程也不到五分鐘…**
  
拿到metrics就是這麼快速，也能進web看看graph，在瀏覽器打上http://prometheus_ip:9090/graph就能看到了，
tab選擇graph也能看到些簡單的圖表
![](1.png)
  
<br></br>
* <h3 id="2">啟動Exporter</h3>
---
<br></br>
既然Prometheus已經起來了，那麼來試著監控些什麼，就下載個node exporter來測試
```
wget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz
tar zxvf node_exporter-1.0.1.linux-amd64.tar.gz
cd node_exporter-1.0.1.linux-amd64
```
<br></br>
裡面一樣是個binary file，執行下去
```
 ./node_exporter --web.listen-address 127.0.0.1:8080
curl 127.0.0.1:8080/metrics
# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 0
go_gc_duration_seconds{quantile="0.25"} 0
go_gc_duration_seconds{quantile="0.5"} 0
go_gc_duration_seconds{quantile="0.75"} 0
go_gc_duration_seconds{quantile="1"} 0
go_gc_duration_seconds_sum 0
go_gc_duration_seconds_count 0
```
<br></br>
cURL測試metrics
```
$ curl localhost:8080/metrics
# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 9.31e-06
go_gc_duration_seconds{quantile="0.25"} 5.488e-05
go_gc_duration_seconds{quantile="0.5"} 0.000112915
go_gc_duration_seconds{quantile="0.75"} 0.000194093
go_gc_duration_seconds{quantile="1"} 0.004481425
go_gc_duration_seconds_sum 0.175059981
go_gc_duration_seconds_count 957
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 8
# HELP go_info Information about the Go environment.
# TYPE go_info gauge
...
```
一樣簡單快速

<br></br>
* <h3 id="3">使用static config進行監控</h3>
---
<br></br>
既然exporter沒問題，那麼是時候建立一個job來get metrics了，就依照<a target="_blank" href="https://prometheus.io/docs/prometheus/latest/getting_started/">這裡的範例</a>，一步步操作吧
  
依照範例，建立prometheus.rules.yml，用於依照需求控制紀錄的方式，能降低監控造成的負擔，此範例是記錄下五分鐘平均的cpu狀態
```:prometheus.rules.yml {linenos=table, linenostart=1}
groups:
- name: cpu-node
  rules:
  - record: job_instance_mode:node_cpu_seconds:avg_rate5m
    expr: avg by (job, instance, mode) (rate(node_cpu_seconds_total[5m]))
```
<br></br>
然後修改prometheus.yml，除了增加rule，也新增job，並[之前]()啟動的exporter
```:prometheus.yml {linenos=table, linenostart=1, hl_lines=[10, "21-33"]}
global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s # Evaluate rules every 15 seconds.

  # Attach these extra labels to all timeseries collected by this Prometheus instance.
  external_labels:
    monitor: 'codelab-monitor'

rule_files:
  - 'prometheus.rules.yml'

scrape_configs:
  - job_name: 'prometheus'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    static_configs:
      - targets: ['localhost:9090']

  - job_name:       'node'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    static_configs:
      - targets: ['localhost:8080', 'localhost:8081']
        labels:
          group: 'production'

      - targets: ['localhost:8082']
        labels:
          group: 'canary'
```
<br></br>
重新啟動prometheus後，就能用去query job instance了
![](2.png)
  
<br></br>
* <h3 id="4">使用file-based service discovery取得target</h3>
---
<br></br>
在實務上，不可能每增加個exporter就重新啟動一次，這時候file-based service discovery就很重要，
這種方式和static config不同，只要修改檔案讓prometheus能去讀取就行，不需要reload
  
先在目錄中建立一個空的file_sd.yml，並修改prometheus.yml
```:prometheus.yml {linenos=table, linenostart=21, hl_lines=[8]}
  - job_name:       'node'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    file_sd_configs:
      - files:
        - ./file_sd.yml
```
<br></br>

重新啟動prometheus後，就發現targets回到空空如也的狀態了
![](3.png)
<br></br>

接下來就是要用file來增加targets了，把前版的prometheus.yml中的static config放到file_sd.yml
```:file_sd.yml {linenos=table, linenostart=1}
- targets: ['localhost:8080', 'localhost:8081']
  labels:
    group: 'production'

- targets: ['localhost:8082']
  labels:
    group: 'canary'
```
<br></br>

接下來不需要重新啟動prometheus，也能新增targets了
![](4.png)
  
<br></br>



* <h3 id=1>使用Pushgateway</h3>
---
<br></br>


Prometheus在設計上是採用pull的模式，但在網路架構的規劃上，並不是所有的target能讓Prometheus去pull，這時候就是Pushgateway出馬的時候了
Pushgateway顧名思義，能讓所需要監控的設備及服務用push的方式將metrics放在Pushgateway，再讓Prometheus來pull
  
如下圖所示：
  
![](5.png)
<br></br>
接下來就試著做一遍了


首先下載並執行Pushgateway，檔案不大十分快速，解開來一樣是binary file
```
$ wget https://github.com/prometheus/pushgateway/releases/download/v1.2.0/pushgateway-1.2.0.linux-amd64.tar.gz
$ tar zxvf pushgateway-1.2.0.linux-amd64.tar.gz
$ cd pushgateway-1.2.0.linux-amd64.tar.gz
```
<br></br>
執行和exporter差不多，一樣用--web.listen-address來決定listen address及port，--persistence.file pg_file能指定一個暫存用的檔案，以防重新啟動時丟失當前的metrics
```
$ ./pushgateway --web.listen-address 0.0.0.0:9091 --persistence.file pg_file
level=info ts=2020-08-18T07:04:00.332Z caller=main.go:83 msg="starting pushgateway" version="(version=1.2.0, branch=HEAD, revision=b7e0167e9574f4f88404dde9653ee1d3c940f2eb)"
level=info ts=2020-08-18T07:04:00.332Z caller=main.go:84 build_context="(go=go1.13.8, user=root@0e823ccfff84, date=20200311-18:51:01"
level=info ts=2020-08-18T07:04:00.334Z caller=main.go:137 listen_address=0.0.0.0:9091
```
<br></br>
接下來就能簡單pull測試一下metrics了
```
$ curl 0.0.0.0:9091/metrics
...
# HELP pushgateway_build_info A metric with a constant '1' value labeled by version, revision, branch, and goversion from which pushgateway was built.
# TYPE pushgateway_build_info gauge
pushgateway_build_info{branch="HEAD",goversion="go1.13.8",revision="b7e0167e9574f4f88404dde9653ee1d3c940f2eb",version="1.2.0"} 1
# HELP pushgateway_http_requests_total Total HTTP requests processed by the Pushgateway, excluding scrapes.
# TYPE pushgateway_http_requests_total counter
pushgateway_http_requests_total{code="200",handler="status",method="get"} 1
```
<br></br>
也能用從web查看，因為現在沒東西push，所以是空空如也
![](6.png)

<br></br>
現在來嘗試push metrics
```
$ cat <<EOF | curl --data-binary @- http://127.0.0.1:9091/metrics/job/some_job/instance/some_instance
# TYPE some_metric counter
some_metric{label="val1"} 42
# TYPE another_metric gauge
# HELP another_metric Just an example.
another_metric 2398.283
EOF
```
<br></br>
嫌指令長也能使用@file name的方式POST檔案
```
$ curl --data-binary @teest.prom http://127.0.0.1:9091/metrics/job/some_job/instance/some_
instance
```
<br></br>
當然除了POST，也能使用DELETE刪除指定的instance
```
$ curl -X DELETE http://127.0.0.1:9091/metrics/job/some_job/instance/some_instance
```
<br></br>
也可以用PUT來覆蓋
```
 curl -X PUT  --data-binary @teest.prom http://127.0.0.1:9091/metrics/job/some_job/instance/some_instance
```
<br></br>
Web也能看到剛才push的metrics
![](7.png)


<br></br>
接著從Pushgateway取得metrics，雖然能用file-based sd，但這次就偷懶一下用static config了，畢竟只是想演示一遍
  
只要在prometheus.yml的target指定Pushgateway
```:prometheus.yml {linenos=table, linenostart=30}
...

  - job_name: 'pushgateway'
    static_configs:
    - targets: ['127.0.0.1:9091']
      labels:
        instance: pushgateway
```
<br></br>
接下來就能看到endpoint多了Pushgateway
![](8.png)
<br></br>
也可以query了
![](9.png)