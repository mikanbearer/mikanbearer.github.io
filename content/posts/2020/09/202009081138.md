---
title: "結巴分詞工具的簡單筆記"
date: 2020-09-08T11:38:55+08:00
draft: false
categories: [DataScience]
tags: [Jieba, Python]
isCJKLanguage: true
layout: "single"
---
這次來使用大名鼎鼎的"結巴中文分詞"了，應該是目前最好的的斷詞工具，之後的實作會用上所以稍微筆記一下
<!--more-->
安裝
```
$ pip install jieba
```
<br></br>
  
### 分詞
---
<br></br>
分詞可使用jieba.cut、jieba.cut_for_search，兩者皆會返回一個generator，
  
而jieba.lcut、jieba.lcut_for_search返回的是list

```shell
$ ipython

In [1]: import jieba

In [2]: type(jieba.cut('', cut_all=True))
Out[2]: generator

In [3]: type(jieba.lcut('', cut_all=True))
Out[3]: generator

```
<br></br>
三種模式的範例
```py
import jieba

seg_list = jieba.cut('在虛構的故事當中尋求真實感的人腦袋一定有問題', cut_all=True)
print('【全模式】：' + '/ '.join(seg_list))
#【全模式】：在/ 虛/ 構/ 的/ 故事/ 當/ 中/ 尋/ 求真/ 實/ 感/ 的/ 人/ 腦/ 袋/ 一定/ 定有/ 問/ 題


seg_list = jieba.cut('在虛構的故事當中尋求真實感的人腦袋一定有問題', cut_all=False)
print('【精確模式】：' + '/ '.join(seg_list))
#【精確模式】：在/ 虛構/ 的/ 故事/ 當中尋/ 求真/ 實感/ 的/ 人/ 腦袋/ 一定/ 有/ 問題


seg_list = jieba.cut_for_search('在虛構的故事當中尋求真實感的人腦袋一定有問題')
print('【搜尋引擎模式】：' + '/ '.join(seg_list))
#【搜尋引擎模式】：在/ 虛構/ 的/ 故事/ 當中尋/ 求真/ 實感/ 的/ 人/ 腦袋/ 一定/ 有/ 問題
```
<br></br>
使用隱藏式馬可夫模型（Hidden Markov Model；縮寫：HMM）
```py
import jieba

seg_list = jieba.cut('在虛構的故事當中尋求真實感的人腦袋一定有問題', cut_all=True, HMM=True)
print('【全模式】：' + '/ '.join(seg_list))
#【全模式】：在/ 虛/ 構/ 的/ 故事/ 當/ 中/ 尋/ 求真/ 實/ 感/ 的/ 人/ 腦/ 袋/ 一定/ 定有/ 問/ 題

seg_list = jieba.cut('在虛構的故事當中尋求真實感的人腦袋一定有問題', cut_all=False, HMM=True)
print('【精確模式】：' + '/ '.join(seg_list))
#【精確模式】：在/ 虛構/ 的/ 故事/ 當中尋/ 求真/ 實感/ 的/ 人/ 腦袋/ 一定/ 有/ 問題

seg_list = jieba.cut_for_search('在虛構的故事當中尋求真實感的人腦袋一定有問題', HMM=True)
print('【搜尋引擎模式】：' + '/ '.join(seg_list))
#【搜尋引擎模式】：在/ 虛構/ 的/ 故事/ 當中尋/ 求真/ 實感/ 的/ 人/ 腦袋/ 一定/ 有/ 問題
```
雖然在這範例看不出分別
<br></br>
Paddle模式
```py
import jieba

jieba.enable_paddle()
seg_list = jieba.cut('在虛構的故事當中尋求真實感的人腦袋一定有問題', use_paddle=True)
print('【Paddle模式】：' + '/ '.join(seg_list))
#【Paddle模式】：在/ 虛構/ 的/ 故事/ 當中尋/ 求真/ 實感/ 的/ 人/ 腦袋/ 一定/ 有/ 問題
```
<br></br>
  
### 自訂辭典
---
<br></br>
載入檔案
```py
jieba.load_userdict('userdict.txt')
```
<br></br>
調整單詞
```py
seg_list = jieba.cut('在虛構的故事當中尋求真實感的人腦袋一定有問題')
print('【調整前】：' + '/ '.join(seg_list))
#【調整前】：在/ 虛構/ 的/ 故事/ 當中尋/ 求真/ 實感/ 的/ 人/ 腦袋/ 一定/ 有/ 問題

jieba.add_word('真實感')
seg_list = jieba.cut('在虛構的故事當中尋求真實感的人腦袋一定有問題')
print('【調整後】：' + '/ '.join(seg_list))
#【調整後】：在/ 虛構/ 的/ 故事/ 當中/ 尋求/ 真實感/ 的/ 人/ 腦袋/ 一定/ 有/ 問題
```
<br></br>
  
### 關鍵詞提取
---
<br></br>
基於TF-IDF的關鍵字提取，公式就不提了…看了頭疼(´；ω；`)
```py
from jieba import analyse as anls

s = '觀自在菩薩。行深般若波羅蜜多時。照見五蘊皆空。度一切苦厄。舍利子。色不異空。空不異色。色即是空。空即是色。受想行識。亦復如是。舍利子。是諸法空相。不生不滅。不垢不淨。不增不減。是故空中無色。無受想行識。無眼耳鼻舌身意。無色聲香味觸法。無眼界。乃至無意識界。無無明。亦無無明盡。乃至無老死。亦無老死盡。無苦集滅道。無智亦無得。以無所得故。菩提薩埵。依般若波羅蜜多故。心無罣礙。無罣礙故。無有恐怖。遠離顛倒夢想。究竟涅槃。三世諸佛。依般若波羅蜜多故。得阿耨多羅三藐三菩提。故知般若波羅蜜多。是大神咒。是大明咒。是無上咒。是無等等咒。能除一切苦。真實不虛。故說般若波羅蜜多咒。即說咒曰。揭諦揭諦。波羅揭諦。波羅僧揭諦。菩提薩婆訶。'

for x, w in anls.extract_tags(s, topK=20, withWeight=True):
    print('%s %s' % (x, w))

'''
波羅蜜 0.6792481535738636
般若 0.5544058480443181
揭諦 0.5433985228590908
菩提 0.31302882206863636
行識 0.2716992614295454
無無明 0.2716992614295454
舍利子 0.25763018851136366
...
'''
```
<br></br>
基於Text rank的關鍵字提取，原理參照[這裡](http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)
```py
for x, w in anls.textrank(s, withWeight=True):
    print('%s %s' % (x, w))

'''
行識 1.0
菩提 0.7557609562914026
老死 0.6746173110357283
揭諦 0.6746173110357283
諸法 0.6294985968338874
空相 0.6259970709534944
觀自 0.5081817230893458
...
'''
```
<br></br>

### 詞性標註
---
<br></br>
標註詞性的範例如下
```py
from jieba import posseg

result = posseg.cut('在虛構的故事當中尋求真實感的人腦袋一定有問題')

for word, flag in result:
    print("{0} {1}".format(word, flag))

'''
在 p
虛構 n
的 uj
故事 n
當中 s
尋 v
求真 nz
...
'''
```
<br></br>

### 返回起始位置
---
<br></br>
```py
from jieba import tokenize

result = tokenize('在虛構的故事當中尋求真實感的人腦袋一定有問題')

for tk in result:
    print("word: {0} \t\t start: {1} \t\t end: {2}".format(tk[0],tk[1],tk[2]))

'''
word: 在 		 start: 0 		 end: 1
word: 虛構 		 start: 1 		 end: 3
word: 的 		 start: 3 		 end: 4
word: 故事 		 start: 4 		 end: 6
...
'''
```