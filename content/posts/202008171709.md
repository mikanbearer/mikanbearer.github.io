---
title: "【Prometheus監控實作-初級篇1】使用Prometheus client library自訂metrics"
date: 2020-08-17T17:09:27+08:00
draft: true
categories: [監控工具]
tags: [Prometheus, Python]
---
作為往後可能需要自訂Exporter的預習，就試著拿[Prometheus client library](https://prometheus.io/docs/instrumenting/clientlibs/)來玩玩…這次使用官方提供的Python版本，藉由這次練習來更加熟練操作Exporter


<!--more-->
* <a href="#1">測試Prometheus Client Library</a>
* <a href="#2">搭配Node exporter text collector</a>
* <a href="#3">搭配Pushgateway</a>

<br></br>
* <h3 id=1>測試Prometheus Client Library</h3>
<br></br>
環境是debian 9及python 3.5.3
```
$  cat /etc/*-release
PRETTY_NAME="Debian GNU/Linux 9 (stretch)"
NAME="Debian GNU/Linux"
VERSION_ID="9"
VERSION="9 (stretch)"
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"

$ python --version
Python 3.5.3
```
<br></br>
先用一下好久沒碰的Pipenv，避免環境弄亂
```
$ pip3 install -U pipenv
$ pipenv --python 3
```
<br></br>
下載prometheus client，然後用shell
```
$ pipenv install prometheus-client
$ pipenv shell
```
<br></br>
[readme.md](https://github.com/prometheus/node_exporter/)中的範例，是使用start_http_server，因為本身就是一個頗為簡短的script，
使用while True來持續執行
```py
from prometheus_client import start_http_server, Summary
import random
import time

# Create a metric to track time spent and requests made.
REQUEST_TIME = Summary('request_processing_seconds', 'Time spent processing request')

# Decorate function with metric.
@REQUEST_TIME.time()
def process_request(t):
    """A dummy function that takes some time."""
    time.sleep(t)

if __name__ == '__main__':
    # Start up the server to expose the metrics.
    start_http_server(8000)
    # Generate some requests.
    while True:
        process_request(random.random())
```
<br></br>
來看看start_http_server的廬山真面目
```
>>> import prometheus_client
>>> import inspect

>>> print(inspect.getsource(prometheus_client.start_http_server))
def start_wsgi_server(port, addr='', registry=REGISTRY):
    """Starts a WSGI server for prometheus metrics as a daemon thread."""
    app = make_wsgi_app(registry)
    httpd = make_server(addr, port, app, ThreadingWSGIServer, handler_class=_SilentHandler)
    t = threading.Thread(target=httpd.serve_forever)
    t.daemon = True
    t.start()

>>> print(inspect.getsource(prometheus_client.start_wsgi_server))
def start_wsgi_server(port, addr='', registry=REGISTRY):
    """Starts a WSGI server for prometheus metrics as a daemon thread."""
    app = make_wsgi_app(registry)
    httpd = make_server(addr, port, app, ThreadingWSGIServer, handler_class=_SilentHandler)
    t = threading.Thread(target=httpd.serve_forever)
    t.daemon = True
    t.start()

```
由此可見start_http_server和start_wsgi_server是同一個function，當這支script執行完了後，Thread也一併結束
<br></br>
執行後一樣cURL測試一下取得的metrics
```
$ curl http://localhost:8000
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 2.17821184e+08
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 2.0774912e+07
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.59764690706e+09
```
<br></br>
當然也可以用custom collector，記得要用REGISTRY.register將collector註冊
```py
from prometheus_client.core import GaugeMetricFamily, REGISTRY
from prometheus_client import start_http_server
import random
import time

class CustomCollector(object):
    def collect(self):
        g = GaugeMetricFamily('my_Gauge', 'Help text', labels=['foo'])
        g.add_metric(['bar'], random.randint(1, 100))
        g.add_metric(['baz'], random.random())
        yield g

REGISTRY.register(CustomCollector())

if __name__ == '__main__':
    start_http_server(8000)
    while True:
        time.sleep(10)
```
<br></br>
可以看到metrics包含剛才測試的custom collector了，看得出start_http_server是指向REGISTRY，而REGISTRY又包含了collector，所以server每pull一次，就會執行一次註冊到REGISTRY的collector
```
$ curl http://localhost:8000 
# HELP my_Gauge Help text
# TYPE my_Gauge gauge
my_Gauge{foo="bar"} 84.0
...
```
大致上是這樣，雖然能動，但單單是這樣似乎有點不太夠，畢竟單獨使用的話功能實在有點陽春

<br></br>  
* <h3 id=2>搭配Node exporter text collector</h3>
<br></br>
[Node exporter](https://github.com/prometheus/node_exporter)出馬的時候又到了，Node Exporter的Textfile collector就能在此發揮作用
  
現在更改剛才測試用的.py如下
```py {linenos=table, linenostart=1, hl_lines=[14]}
from prometheus_client.core import GaugeMetricFamily, REGISTRY
from prometheus_client import write_to_textfile
import random

class CustomCollector(object):
    def collect(self):
        g = GaugeMetricFamily('my_Gauge', 'Help text', labels=['foo'])
        g.add_metric(['bar'], random.randint(1, 100))
        g.add_metric(['baz'], random.random())
        yield g

REGISTRY.register(CustomCollector())

write_to_textfile('test.prom', REGISTRY)
```
這樣就會將registry的中的metrics通通輸出到一個叫做"test.prom"的file裡了
<br></br>
之後Node exporter再使用--collector.textfile.directory這個flag就能取得指定目錄下*.prom內的metrics，範例指令如下：
```
./node_exporter  --web.listen-address="0.0.0.0:9100" --collector.textfile.directory ~/test
```
<br></br>
一樣測試一下
```
$ curl http://127.0.0.1:9000/metrics
...
my_Gauge{foo="bar"} 90
my_Gauge{foo="baz"} 0.7249480740635738
```
這樣就能pull file裡面的東西了
  
如此一來不只能用crontab之類的來排程，甚至在其他程式裡加上write_to_textfile，到時候只需要讓node_exporter去指定目錄抓就好，彈性又便利，這是這做法會犧牲掉Counter

<br></br>
* <h3 id=3>搭配Pushgateway</h3>
<br></br>
Client library除了能使用write_to_textfile來搭配Node exporter，也能配合Pushgateway
  
修改剛才測試的py如下：
```py {linenos=table, linenostart=1, hl_lines=[14]}
from prometheus_client.core import GaugeMetricFamily, REGISTRY
from prometheus_client import push_to_gateway
import random

class CustomCollector(object):
    def collect(self):
        g = GaugeMetricFamily('my_Gauge', 'Help text', labels=['foo'])
        g.add_metric(['bar'], random.randint(1, 100))
        g.add_metric(['baz'], random.random())
        yield g

REGISTRY.register(CustomCollector())

push_to_gateway('localhost:9091', job='batchA', registry=REGISTRY)
```
<br></br>
cURL測試一下
```
$ curl http://localhost:9091/metrics
...
# HELP python_gc_collections_total Number of times this generation was collected
# TYPE python_gc_collections_total counter
python_gc_collections_total{generation="0",instance="",job="batchA"} 42
python_gc_collections_total{generation="1",instance="",job="batchA"} 3
python_gc_collections_total{generation="2",instance="",job="batchA"} 0
# HELP python_gc_objects_collected_total Objects collected during gc
# TYPE python_gc_objects_collected_total counter
python_gc_objects_collected_total{generation="0",instance="",job="batchA"} 145
python_gc_objects_collected_total{generation="1",instance="",job="batchA"} 25
python_gc_objects_collected_total{generation="2",instance="",job="batchA"} 0
# HELP python_gc_objects_uncollectable_total Uncollectable object found during GC
# TYPE python_gc_objects_uncollectable_total counter
python_gc_objects_uncollectable_total{generation="0",instance="",job="batchA"} 0
python_gc_objects_uncollectable_total{generation="1",instance="",job="batchA"} 0
python_gc_objects_uncollectable_total{generation="2",instance="",job="batchA"} 0
# HELP python_info Python platform information
# TYPE python_info gauge
python_info{implementation="CPython",instance="",job="batchA",major="3",minor="6",patchlevel="8",version="3.6.8"} 1
```
<br></br>
完